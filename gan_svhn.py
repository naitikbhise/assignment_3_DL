# -*- coding: utf-8 -*-
"""GAN_svhn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VI9Tz2Jz_76Ga11NqsXXy2VFNqP6QZlZ
"""

from torchvision.datasets import utils
import torch.utils.data as data_utils
import torch
import os
import numpy as np
from torch import nn
from torch.distributions.normal import Normal
import torch.distributions as d
import math
from torch.nn.modules import upsampling
from torch.functional import F
from torch.optim import Adam

import torch
import torch.optim as optim
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.models as models
import torchvision.transforms as transforms
from torch.utils.data import dataset
from torch.autograd import Variable
from torchvision.utils import save_image
import numpy as np 
import matplotlib.pyplot as plt
from urllib.request import urlretrieve
from os.path import isfile, isdir
from tqdm import tqdm
# %matplotlib inline

#Importer les dossiers
import classify_svhn as svhn
import score_fid as fid

#Importer les biblioth√®ques de python

cuda = torch.cuda.is_available()

data_dir = '.'

if not isdir(data_dir):
    raise Exception("Data directory doesn't exist!")

class DLProgress(tqdm):
    last_block = 0

    def hook(self, block_num=1, block_size=1, total_size=None):
        self.total = total_size
        self.update((block_num - self.last_block) * block_size)
        self.last_block = block_num

if not isfile(data_dir + "train_32x32.mat"):
    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='SVHN Training Set') as pbar:
        urlretrieve(
            'http://ufldl.stanford.edu/housenumbers/train_32x32.mat',
            data_dir + 'train_32x32.mat',
            pbar.hook)

if not isfile(data_dir + "test_32x32.mat"):
    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='SVHN Testing Set') as pbar:
        urlretrieve(
            'http://ufldl.stanford.edu/housenumbers/test_32x32.mat',
            data_dir + 'test_32x32.mat',
            pbar.hook)
        
#Data Loader
def get_data_loader(dataset_location, batch_size):

    transform = transforms.Compose([
                transforms.ToTensor(),
                transforms.Normalize((.5, .5, .5), (.5, .5, .5))])


    trainvalid = torchvision.datasets.SVHN(
        dataset_location, split='train',
        download=True,
        transform=transform
    )

    trainset_size = int(len(trainvalid) * 0.9)
    trainset, validset = dataset.random_split(
        trainvalid,
        [trainset_size, len(trainvalid) - trainset_size]
    )

    trainloader = torch.utils.data.DataLoader(
        trainset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=2
    )

    validloader = torch.utils.data.DataLoader(
        validset,
        batch_size=batch_size,
    )

    testloader = torch.utils.data.DataLoader(
        torchvision.datasets.SVHN(
            dataset_location, split='test',
            download=True,
            transform=transform
        ),
        batch_size=batch_size,
    )

    return trainloader, validloader, testloader

!mkdir Q3_1
!rm -r Q3_1/*

def sample_generator(model, num_samples, latent_dim, name):
   noise = torch.randn(num_samples, latent_dim).to('cuda')
   noise.require_grad = False
   gen_samples = model(noise).to('cuda')
   gen_samples = gen_samples.view(-1, 3, 32, 32)
   save_image(gen_samples.data.view(num_samples, 3, 32, 32).cpu(), 'Q3_1/3_1_1_GAN_' + str(name) + '.png', nrow = 10, normalize=True)

def disentangled_representation(model, dim, eps):
   z = torch.randn(1, 100).to('cuda')
   sample = model(z).to('cuda')
   sample = sample.view(-1, 3, 32, 32)
   save_image(sample.data.view(-1, 3, 32, 32).cpu(), 'Q3_2/3_1_2_GAN_before.png', nrow = 1, normalize=True)
   z = z.repeat(100, 1)
   for i in range(dim):
       z[i][i] = z[i][i] + eps
   sample = model(z).to('cuda')
   sample = sample.view(-1, 3, 32, 32)
   save_image(sample.data.view(-1, 3, 32, 32).cpu(), 'Q3_2/3_1_2_GAN_afetr.png', nrow = 10, normalize=True)

!mkdir Q3_2
!rm -r Q3_2/*

def interpolation(model):
  alphas = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
  z0 = torch.randn(1, 100).to('cuda')
  z0 = z0.repeat(10, 1)
  z1 = torch.randn(1, 100).to('cuda')
  z1 = z1.repeat(10, 1)
  sample_0 = model(z0).to('cuda')
  sample_1 = model(z1).to('cuda')
  #z = torch.zeros(11,1)
  #z = torch.zeros(z0.size())
  #z1 = z1.repeat(100, 1)
  a = torch.zeros(10, 100).to('cuda')
  for i, alpha in enumerate(alphas):
      a[i-1] = z0[i-1] * alpha + (1 - alpha) * z1[i-1]
      #print(torch.FloatTensor(z))
      sample = model(a).to('cuda')
      sample = sample.view(-1, 3, 32, 32)
      sample[i-1] = alpha * sample_0[i-1] + (1 - alpha) * sample_1[i-1]
      sample = sample.view(-1, 3, 32, 32)
  save_image(sample.data.view(-1, 3, 32, 32).cpu(), ('Q3_3/3_1_3_GAN_latent_inter.png'), nrow = 10 ,normalize=True)
  save_image(sample.data.view(-1, 3, 32, 32).cpu(), ('Q3_3/3_1_3_GAN_data_inter.png'), nrow = 10 ,normalize=True)

!mkdir Q3_3
!rm -r Q3_3/*

def image_generator(model):
  for i in range(1000):
     z = torch.randn(1, 100).to('cuda')
     sample = model(z).to('cuda')
     save_image(sample.data.view(-1, 3, 32, 32).cpu(), ('Q3_4/subfolder/sample_' +str(i)+'.png'),normalize=True)


!mkdir Q3_4
!mkdir Q3_4/subfolder
!rm -r Q3_4/subfolder/*

epochs = 20
FID = []
for epoch in tqdm.trange(epochs, leave=True):
   track = trainVAE(epoch)
   testVAE(epoch)

   sample_generator(model, 100, 100, epoch)

   image_generator(model)
   FID.append(show_fid('svhn_classifier.pt', 'Q3_4'))

disentangled_representation(model, 100, 0.6)
interpolation(model)
print("best FID:", np.min(FID))

"""**Loss function** - The wasserstein one. Though we use a DCGAN for the work. DCGAN is the gan with the Binary cross Entropy loss function."""

def loss_fn2(Discriminator,x,y,batch_size,lamb=10):
    x = x.to('cuda')
    y = y.to('cuda')
    real_data = torch.mean(Discriminator(x))
    #print("D_real:",real_data)
    fake_data = torch.mean(Discriminator(y))
    #print("D_fake:",real_data)
    a = torch.randn([batch_size, 3,32,32 ]).float().cuda()
    #p = torch.from_numpy(next(sm.distribution1(0))).float()
    #q = torch.from_numpy(next(sm.distribution1(-1))).float()
    #print(x.size())
    #print(y.size())
    z = a*x+(1-a)*y
    input = torch.autograd.Variable(z,requires_grad= True)
    output = Discriminator(input)
    grad = torch.autograd.grad(output, input, grad_outputs=torch.ones(output.size()).cuda(),create_graph=True, only_inputs=True,
                               retain_graph=True)[0].contiguous()
    #print(grad.size)
    grad = grad.view(grad.size(0), -1)
    grad = grad.norm(2,dim =1)
    grad = grad - 1
    grad = grad**2  #Gradient penalty
    #grad = torch.sqrt(grad)
    return -(real_data-fake_data-lamb*grad.mean())

"""This is the Generator model which I use and I arrived here after a long search."""

class Generator(nn.Module):
  def __init__(self):
    super(Generator,self).__init__()
    #self.init_size = 8
    self.linear = nn.Linear(100,128*8**2)
    self.conv = nn.Sequential(
        nn.BatchNorm2d(128),
        nn.Upsample(scale_factor=2),
        nn.Conv2d(128,128,3, stride =1,padding =1),
        nn.BatchNorm2d(128,0.8),
        nn.LeakyReLU(0.2,inplace=True),
        nn.Upsample(scale_factor=2),
        nn.Conv2d(128,64,3, stride =1,padding =1),
        nn.BatchNorm2d(64,0.8),
        nn.LeakyReLU(0.2,inplace=True),
        #nn.Upsample(scale_factor=2),
        nn.Conv2d(64,3,3, stride =1,padding =1),
        nn.Tanh(),
    )
  def forward(self,z):
    out = self.linear(z)
    out = out.view(out.shape[0],128,8,8)
    return self.conv(out)

"""The Discriminator"""

class Discriminator(nn.Module):
  def __init__(self):
    super(Discriminator,self).__init__()
    
    self.model = nn.Sequential(
        nn.Conv2d(3,16,3,2,1),
        nn.LeakyReLU(0.2,inplace=True),nn.Dropout2d(0.25),
        nn.Conv2d(16,32,3,2,1),
        nn.LeakyReLU(0.2,inplace=True),nn.Dropout2d(0.25),
        nn.BatchNorm2d(32,0.8),
        nn.Conv2d(32,64,3,2,1),
        nn.LeakyReLU(0.2,inplace=True),nn.Dropout2d(0.25),
        nn.BatchNorm2d(64,0.8),
        nn.Conv2d(64,128,3,2,1),
        nn.LeakyReLU(0.2,inplace=True),nn.Dropout2d(0.25),
        nn.BatchNorm2d(128,0.8),
    )
    self.linear = nn.Sequential(
        nn.Linear(128* 2 *2,1),
        nn.Sigmoid()
    )
  def forward(self,img):
    out = self.model(img)
    out = out.view(out.shape[0],-1)
    out = self.linear(out)
    return out

"""Sample saving"""

def sample_generator(Generator,num_samples, latent_dim, name):
  noise = torch.randn(num_samples, latent_dim).to('cuda')
  noise.require_grad = False
  gen_samples = Generator(noise).to('cuda')
  gen_samples = gen_samples.view(-1, 3, 32, 32)
  save_image(gen_samples.data.view(num_samples, 3, 32, 32).cpu(), 'result/sample_' + str(name) + '.png', nrow = 10,normalize=True)

"""Training stuff and inserting of many parameters.
Optimizer = Adam and lr are the learning rates

Try to train the generator after 5 steps of discriminator
"""

def train(Discriminator, Generator, trainloader, latent_dim, batch_size, epochs):
    
    

    # ## optimizers
    optimizer_G = torch.optim.Adam(Generator.parameters(), lr=1e-4,betas=[0.5,0.9])
    optimizer_D = torch.optim.Adam(Discriminator.parameters(), lr=1e-3,betas=[0.5,0.9])

    #FID = []
    for e in range(epochs):
        Discriminator.train()
        Generator.train()
        for i, (img, _) in enumerate(trainloader):
            batch_size = img.shape[0]
            update_d = e * batch_size + i + 1
            D_x = img
            #print(img.size())
            noise = torch.randn(batch_size, latent_dim).to('cuda')
            D_y = Generator(noise)
            #D_y = D_y/2+1
            #print(D_y.size())
            loss = loss_fn2(Discriminator,D_x,D_y,batch_size)
            Discriminator.zero_grad()
            loss.backward()
            optimizer_D.step()
            
            if update_d % 5== 0:
                noise = torch.randn(batch_size, latent_dim).to('cuda')
                D_y = Generator(noise)
                #D_y = D_y/2+1
                Generator.zero_grad()
                D_loss_fake = Discriminator(D_y)
                loss_g = -(D_loss_fake.mean())
                loss_g.backward()
                optimizer_G.step()
                
        
        print ('Epoch: ', e, 'step: ', i, 'Discriminator loss: ', loss.mean().cpu().data.numpy(),
            'Generator loss: ', loss_g.mean().cpu().data.numpy())
        sample_generator(Generator, 100, latent_dim,e)
        
        image_generator(Generator)
          
        #FID.append(show_fid('svhn_classifier.pt', 'Q3_4'))
    #print("best FID:", np.min(FID))

!mkdir result

!rm Q3_4/subfolder/*

"""Run the experiment"""

cuda = torch.cuda.is_available()
D = Discriminator().to('cuda')
G = Generator().to('cuda')
trainloader, validloader, testloader = get_data_loader('.', 512)
train(D, G, trainloader, 100, 64, 200)

cuda = torch.cuda.is_available()
D = Discriminator().to('cuda')
G = Generator().to('cuda')
trainloader, validloader, testloader = get_data_loader('.', 512)
train(D, G, trainloader, 100, 64, 200)

"""Save the models for the Generator and Discriminator"""

torch.save(G.state_dict(), './gen_' + 'Gen' + '.pt')
torch.save(D.state_dict(), './dis_' + 'Dis' + '.pt')

!zip -r results.zip result/

def disentangled_representation(model, dim, eps,name):
    z = torch.randn(1, 100).to('cuda')
    #z = z.repeat(1, 100)
    for i in range(dim):
        z[i] = z[i] + eps
    sample = model(z)
    sample = sample.view(-1, 3, 32, 32)
    save_image(sample.data.view(-1, 3, 32, 32).cpu(), 'res1/sample_' + str(name) + '.png', nrow = 10,normalize=True
)

D = torch.load('dis_Dis.pt',map_location = 'cpu')

G = torch.load('gen_Gen.pt',map_location= 'cuda')

G = Generator

disentangled_representation(G,10,1,'ggan')

def interpolation(model, name1, name2):
    alphas = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
    z0 = torch.randn(1, 100).to('cuda')
    z0 = z0.repeat(100, 1)
    z1 = torch.randn(1, 100).to('cuda')
    z1 = z1.repeat(100, 1)
    sample_0 = model(z0).to('cuda')
    sample_1 = model(z1).to('cuda')
    #z = torch.zeros(11,1)
    #z = torch.zeros(z0.size())
    #z1 = z1.repeat(100, 1)
    for i, alpha in enumerate(alphas):
        a = z0 * alpha + (1 - alpha) * z1
        #print(torch.FloatTensor(z))
        sample = model(a).to('cuda')
        sample = sample.view(-1, 3, 32, 32)
        save_image(sample.data.view(-1, 3, 32, 32).cpu(), ('3.2.1/sample_' +str(i)+'.png'), nrow = 10,normalize=True)
        sample = alpha * sample_0 + (1 - alpha) * sample_1
        sample = sample.view(-1, 3, 32, 32)
        save_image(sample.data.view(-1, 3, 32, 32).cpu(), ('3.2.2/sample_3'+str(i)+'.png'), nrow = 10,normalize=True)

!mkdir 3.2.1
!mkdir 3.2.2

import copy
import pickle

# model stuff    
model = mymodel()
model.load_state_dict(torch.load('gen_Gen.pt'))

interpolation(G,'gand','gand1')

import imageio
imageio.mimsave('results/training_{}_epochs.gif'.format(epochs),
                            training_progress_images)

def font_image(model,number):
  for i in range(number):
    a = torch.randn(1, 100).to('cpu')
    sample = model(a)
    sample = sample.view(-1, 3, 32, 32)
    save_image(sample.data.view(-1, 3, 32, 32).cpu(), 'result/sample_' + str(number) + '.png', nrow = 1,normalize=True)

font_image(G,1000)

fid.show_fid('svhn_classifier.pt', './3.2.1')

import argparse
import os
import torchvision
import torchvision.transforms as transforms
import torch
import classify_svhn
from classify_svhn import Classifier
import scipy as sp

SVHN_PATH = "svhn"
PROCESS_BATCH_SIZE = 32


def get_sample_loader(path, batch_size):
    """
    Loads data from `[path]/samples`

    - Ensure that path contains only one directory
      (This is due ot how the ImageFolder dataset loader
       works)
    - Ensure that ALL of your images are 32 x 32.
      The transform in this function will rescale it to
      32 x 32 if this is not the case.

    Returns an iterator over the tensors of the images
    of dimension (batch_size, 3, 32, 32)
    """
    data = torchvision.datasets.ImageFolder(
        path,
        transform=transforms.Compose([
            transforms.Resize((32, 32), interpolation=2),
            classify_svhn.image_transform
        ])
    )
    data_loader = torch.utils.data.DataLoader(
        data,
        batch_size=batch_size,
        num_workers=2,
    )
    return data_loader


def get_test_loader(batch_size):
    """
    Downloads (if it doesn't already exist) SVHN test into
    [pwd]/svhn.

    Returns an iterator over the tensors of the images
    of dimension (batch_size, 3, 32, 32)
    """
    testset = torchvision.datasets.SVHN(
        SVHN_PATH, split='test',
        download=True,
        transform=classify_svhn.image_transform
    )
    testloader = torch.utils.data.DataLoader(
        testset,
        batch_size=batch_size,
    )
    return testloader


def extract_features(classifier, data_loader):
    """
    Iterator of features for each image.
    """
    with torch.no_grad():
        for x, _ in data_loader:
            h = classifier.extract_features(x).numpy()
            for i in range(h.shape[0]):
                yield h[i]


def calculate_fid_score(sample_feature_iterator,
                        testset_feature_iterator):
    sample_feature = []
    test_feature = []
    for i in range(sample_feature_iterator):
        sample_feature.append(i)
    mu = np.mean(sample_feature, axis = 0)
    sigma = np.cov(sample_feature, rowvar = False)
    for j in range(testset_feature_iterator):
        testset_feature.append(j)
    mu1 = np.mean(testset_feature, axis = 0)
    sigma1 = np.cov(testset_feature, rowvar = False)
    fid = np.linalg.norm(mu1 - mu)**2 + np.trace(sigma + sigma1 - 2 * linalg.sqrtm(sigma.dot(sigma1)+eps*np.eye(len(sigma))))
    raise NotImplementedError(
        print("TO BE IMPLEMENTED.Part of Assignment 3 Quantitative Evaluations")
    )
    return fid

def show_fid(model, directory):
    classifier = torch.load(model, map_location = 'cpu')
    classifier.eval()
    sample_loader = get_sample_loader(directory, PROCESS_BATCH_SIZE)
    sample_f = extract_features(classifier, sample_loader)
    test_loader = get_test_loader(PROCESS_BATCH_SIZE)
    test_f = extract_features(classifier, test_loader)
    fid_score = calculate_fid_score(sample_f, test_f)
    print("FID score:", fid_score)
    return fid_score

show_fid('svhn_classifier.pt', '/content/3.2.2')

!pwd

