{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q3_VAE_similar-to-GAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "r1D5oUpkzfx6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mini_batch_size = 128\n",
        "first_channel = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tU9DypYVzlgA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import utils\n",
        "import torch.utils.data as data_utils\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch.distributions.normal import Normal\n",
        "import torch.distributions as d\n",
        "import math\n",
        "from torch.nn.modules import upsampling\n",
        "from torch.functional import F\n",
        "from torch.optim import Adam\n",
        "\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import dataset\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import save_image\n",
        "import matplotlib.pyplot as plt\n",
        "from urllib.request import urlretrieve\n",
        "from os.path import isfile, isdir\n",
        "import tqdm\n",
        "%matplotlib inline\n",
        "\n",
        "from urllib.request import urlretrieve\n",
        "from os.path import isfile, isdir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iRtLIKjrzn7n",
        "colab_type": "code",
        "outputId": "d316615f-d913-4d99-be08-922cf8185acb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "data_dir = '.'\n",
        "\n",
        "if not isdir(data_dir):\n",
        "    raise Exception(\"Data directory doesn't exist!\")\n",
        "\n",
        "class DLProgress(tqdm.tqdm):\n",
        "    last_block = 0\n",
        "\n",
        "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
        "        self.total = total_size\n",
        "        self.update((block_num - self.last_block) * block_size)\n",
        "        self.last_block = block_num\n",
        "\n",
        "if not isfile(data_dir + \"train_32x32.mat\"):\n",
        "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='SVHN Training Set') as pbar:\n",
        "        urlretrieve(\n",
        "            'http://ufldl.stanford.edu/housenumbers/train_32x32.mat',\n",
        "            data_dir + 'train_32x32.mat',\n",
        "            pbar.hook)\n",
        "\n",
        "if not isfile(data_dir + \"test_32x32.mat\"):\n",
        "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='SVHN Testing Set') as pbar:\n",
        "        urlretrieve(\n",
        "            'http://ufldl.stanford.edu/housenumbers/test_32x32.mat',\n",
        "            data_dir + 'test_32x32.mat',\n",
        "            pbar.hook)\n",
        "        \n",
        "\n",
        "def get_data_loader(dataset_location, batch_size):\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((.5, .5, .5), (.5, .5, .5))])\n",
        "\n",
        "\n",
        "    trainvalid = torchvision.datasets.SVHN(\n",
        "        dataset_location, split='train',\n",
        "        download=True,\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    trainset_size = int(len(trainvalid) * 0.9)\n",
        "    trainset, validset = dataset.random_split(\n",
        "        trainvalid,\n",
        "        [trainset_size, len(trainvalid) - trainset_size]\n",
        "    )\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "        trainset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "    validloader = torch.utils.data.DataLoader(\n",
        "        validset,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "\n",
        "    testloader = torch.utils.data.DataLoader(\n",
        "        torchvision.datasets.SVHN(\n",
        "            dataset_location, split='test',\n",
        "            download=True,\n",
        "            transform=transform\n",
        "        ),\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "\n",
        "    return trainloader, validloader, testloader\n",
        "\n",
        "# Data specifications: number of channels and datapath\n",
        "nc = 3\n",
        "dataset_location = \".\"\n",
        "\n",
        "trainloader, validloader, testloader = get_data_loader('.', mini_batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: ./train_32x32.mat\n",
            "Using downloaded and verified file: ./test_32x32.mat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wWts7eKxGoqA",
        "colab_type": "code",
        "outputId": "dd6c8e51-9efe-47fb-a734-cd0a06dc7063",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        }
      },
      "cell_type": "code",
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VAE, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3,16,3,2,1),\n",
        "            nn.LeakyReLU(0.2,inplace=True),nn.Dropout2d(0.25),\n",
        "            nn.Conv2d(16,32,3,2,1),\n",
        "            nn.LeakyReLU(0.2,inplace=True),nn.Dropout2d(0.25),\n",
        "            nn.BatchNorm2d(32,0.8),\n",
        "            nn.Conv2d(32,64,3,2,1),\n",
        "            nn.LeakyReLU(0.2,inplace=True),nn.Dropout2d(0.25),\n",
        "            nn.BatchNorm2d(64,0.8),\n",
        "            nn.Conv2d(64,128,3,2,1),\n",
        "            nn.LeakyReLU(0.2,inplace=True),nn.Dropout2d(0.25),\n",
        "            nn.BatchNorm2d(128,0.8))\n",
        "        \n",
        "        self.en_mean = nn.Linear(128*(2*2), 100)\n",
        "        self.en_log_var = nn.Linear(128*(2*2), 100)\n",
        "        self.fully = nn.Linear(100, 512*(4*4))\n",
        "        \n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128,128,3, stride =1,padding =1),\n",
        "            nn.BatchNorm2d(128,0.8),\n",
        "            nn.LeakyReLU(0.2,inplace=True),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128,64,3, stride =1,padding =1),\n",
        "            nn.BatchNorm2d(64,0.8),\n",
        "            nn.LeakyReLU(0.2,inplace=True),\n",
        "            #nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(64,3,3, stride =1,padding =1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "        \n",
        "\n",
        "    def encode(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = x.view(-1, 128*(2*2))\n",
        "\n",
        "        eva = self.en_mean(x)\n",
        "        log_var = self.en_log_var(x)\n",
        "\n",
        "        return eva, log_var\n",
        "\n",
        "    def sampler(self, eva, log_var):\n",
        "        std = torch.exp(0.5 * log_var)\n",
        "        eps = torch.randn_like(std)\n",
        "\n",
        "        return eps * std + eva\n",
        "\n",
        "    def decode(self, z):\n",
        "        z = self.fully(z)\n",
        "        z = z.view(-1, 128,8,8)\n",
        "        z = self.decoder(z)\n",
        "        return z\n",
        "\n",
        "    def forward(self, x):\n",
        "        eva, log_var = self.encode(x)\n",
        "        z = self.sampler(eva, log_var)\n",
        "        return self.decode(z), eva, log_var\n",
        "\n",
        "\n",
        "model = VAE()\n",
        "\n",
        "print(model)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    use_cuda = True\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    use_cuda = False\n",
        "\n",
        "print(device)\n",
        "\n",
        "\n",
        "model = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VAE(\n",
            "  (encoder): Sequential(\n",
            "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
            "    (2): Dropout2d(p=0.25)\n",
            "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace)\n",
            "    (5): Dropout2d(p=0.25)\n",
            "    (6): BatchNorm2d(32, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (8): LeakyReLU(negative_slope=0.2, inplace)\n",
            "    (9): Dropout2d(p=0.25)\n",
            "    (10): BatchNorm2d(64, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (12): LeakyReLU(negative_slope=0.2, inplace)\n",
            "    (13): Dropout2d(p=0.25)\n",
            "    (14): BatchNorm2d(128, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (en_mean): Linear(in_features=512, out_features=100, bias=True)\n",
            "  (en_log_var): Linear(in_features=512, out_features=100, bias=True)\n",
            "  (fully): Linear(in_features=100, out_features=8192, bias=True)\n",
            "  (decoder): Sequential(\n",
            "    (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): Upsample(scale_factor=2, mode=nearest)\n",
            "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): BatchNorm2d(128, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace)\n",
            "    (5): Upsample(scale_factor=2, mode=nearest)\n",
            "    (6): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): BatchNorm2d(64, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): LeakyReLU(negative_slope=0.2, inplace)\n",
            "    (9): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): Tanh()\n",
            "  )\n",
            ")\n",
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "u80bq-LjzuvX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def loss_function(recon_x, x, eva, log_var):\n",
        "    \n",
        "    loss = torch.nn.functional.mse_loss(recon_x, x, reduction='sum')\n",
        "        \n",
        "    return loss\n",
        "\n",
        "\n",
        "def trainVAE(epoch):\n",
        "    track = [[\"loss\", \"eva\", \"log_var\"]]\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch_idx, (data, _) in enumerate(trainloader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        recon_batch, eva, log_var = model(data)\n",
        "        loss = loss_function(recon_batch, data, eva, log_var)\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        track.append([loss, eva, log_var])\n",
        "    train_loss = - train_loss  / len(trainloader.dataset)\n",
        "    print('====> Epoch: {} ELBO for training: {:.4f}'.format(\n",
        "          epoch, train_loss  ))\n",
        "    return track\n",
        "    \n",
        "\n",
        "def testVAE(epoch):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    for batch_idx, (data, _) in enumerate(validloader):\n",
        "        data = data.to(device)\n",
        "        recon_batch, eva, log_var = model(data)\n",
        "        loss = loss_function(recon_batch, data, eva, log_var)\n",
        "        test_loss += loss.item()\n",
        "    test_loss = - test_loss  / len(validloader.dataset)\n",
        "    print('====> Epoch: {} ELBO for validation: {:.4f}'.format(\n",
        "          epoch, test_loss))\n",
        "\n",
        "    \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K1IPbZDd3jyE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ". Q3.1"
      ]
    },
    {
      "metadata": {
        "id": "W4F7GDKMz0ZI",
        "colab_type": "code",
        "outputId": "0cce0b95-f2bb-4872-9621-4206dc13c8c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir Q3_1\n",
        "!rm -r Q3_1/*\n",
        "\n",
        "def sample_generator(model, num_samples, latent_dim#, update_d\n",
        "                     , name):\n",
        "    noise = torch.randn(num_samples, latent_dim).to('cuda')\n",
        "    noise.require_grad = False\n",
        "    gen_samples = model.decode(noise).to('cuda')\n",
        "    gen_samples = gen_samples.view(-1, 3, 32, 32)\n",
        "    save_image(gen_samples.data.view(num_samples, 3, 32, 32).cpu(), 'Q3_1/3_1_1_VAE_' + str(name) + '.png', nrow = 10, normalize=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘Q3_1’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JgB0DLxGY60S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ". Q3.2"
      ]
    },
    {
      "metadata": {
        "id": "HLAteK5eYzWl",
        "colab_type": "code",
        "outputId": "034051d6-b7c2-4a47-bf69-1b30969ccf35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "def disentangled_representation(model, dim, eps):\n",
        "    z = torch.randn(1, 100)\n",
        "    sample = model.decode(z).to('cuda')\n",
        "    sample = sample.view(-1, 3, 32, 32)\n",
        "    save_image(sample.data.view(-1, 3, 32, 32).cpu(), 'Q3_2/3_1_2_VAE_before.png', nrow = 1, normalize=True)\n",
        "    z = z.repeat(100, 1)\n",
        "    for i in range(dim):\n",
        "        z[i][i] = z[i][i] + eps\n",
        "    sample = model.decode(z).to('cuda')\n",
        "    sample = sample.view(-1, 3, 32, 32)\n",
        "    save_image(sample.data.view(-1, 3, 32, 32).cpu(), 'Q3_2/3_1_2_VAE_afetr.png', nrow = 10, normalize=True)\n",
        "    \n",
        "def disentangled_representation(model, dim, eps):\n",
        "    z = torch.randn(1, 100).to('cuda')\n",
        "    sample = model.decode(z).to('cuda')\n",
        "    sample = sample.view(-1, 3, 32, 32)\n",
        "    save_image(sample.data.view(-1, 3, 32, 32).cpu(), 'Q3_2/3_1_2_VAE_before.png', nrow = 1, normalize=True)\n",
        "    z1 = z\n",
        "    z = z.repeat(100, 1)\n",
        "    for i in range(dim):\n",
        "        z[i][i] = z[i][i] + eps\n",
        "    outputs = model.decode(z)\n",
        "    outputs = outputs.view(-1, 3, 32, 32)\n",
        "    difference = torch.abs(outputs - sample).view(100,-1)\n",
        "    #sample = outputs.view(-1, 3, 32, 32)\n",
        "    #save_image(sample.data.view(-1, 3, 32, 32).cpu(), 'Q3_2/3_1_2_GAN_afetr.png', nrow = 10, normalize=True)\n",
        "\n",
        "    sum_dif = torch.sum(difference, dim=1).detach().cpu().numpy()\n",
        "    top_sum_diff_indcs = np.unravel_index(np.argsort(sum_dif, axis=None), sum_dif.shape)[0]\n",
        "    # top_sum_diff_indcs = [top_sum_diff_indcs[x] for x in range(9, 100, 10)]\n",
        "    top_sum_diff_indcs = top_sum_diff_indcs[-10:]\n",
        "    print(top_sum_diff_indcs)\n",
        "    z = z1.repeat(10,1)\n",
        "    for i in range(10):\n",
        "        #if i in top_sum_diff_indcs:\n",
        "            #z[i][i] = z[i][i] + eps\n",
        "        a = top_sum_diff_indcs[i]\n",
        "        z[i][a] = z[i][a] + eps\n",
        "    outputs = model.decode(z)\n",
        "    sample = outputs.view(-1, 3, 32, 32)\n",
        "    save_image(sample.data.view(-1, 3, 32, 32).cpu(), 'Q3_2/3_1_2_VAE_after.png', nrow = 10, normalize=True)\n",
        "    \n",
        "    \n",
        "!mkdir Q3_2\n",
        "!rm -r Q3_2/*"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘Q3_2’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NkXR8oSty2xH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ". Q3.3"
      ]
    },
    {
      "metadata": {
        "id": "Xye7b6Tvy66X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def interpolation(model):\n",
        "    alphas = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
        "    z0 = torch.randn(1, 100).to('cuda')\n",
        "    z0 = z0.repeat(11, 1)\n",
        "    z1 = torch.randn(1, 100).to('cuda')\n",
        "    z1 = z1.repeat(11, 1)\n",
        "    sample_0 = model.decode(z0).to('cuda').clone().detach()\n",
        "    sample_1 = model.decode(z1).to('cuda').clone().detach()\n",
        "    z_inter = torch.zeros(11, 100).to('cuda')\n",
        "    sample_data_inter = torch.zeros(11, 3, 32, 32).to('cuda')\n",
        "    for i, alpha in enumerate(alphas):\n",
        "        z_inter[i-1] = alpha * z0[i-1] + (1 - alpha) * z1[i-1]\n",
        "        sample_data_inter[i-1] = alpha * sample_0[i-1] + (1 - alpha) * sample_1[i-1]\n",
        "        \n",
        "    sample_latent_inter = model.decode(z_inter).to('cuda')\n",
        "    sample_latent_inter = sample_latent_inter.view(-1, 3, 32, 32)\n",
        "    save_image(sample_latent_inter.data.view(-1, 3, 32, 32).cpu(), ('Q3_3/3_1_3_VAE_latent_inter.png'), nrow = 11 ,normalize=True)\n",
        "    save_image(sample_data_inter.data.view(-1, 3, 32, 32).cpu(), ('Q3_3/3_1_3_VAE_data_inter.png'), nrow = 11 ,normalize=True)\n",
        "\n",
        "\n",
        "!mkdir Q3_3\n",
        "!rm -r Q3_3/*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JxTsQ13o3JFm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ". Load \"classify_svhn.py\" and \"svhn_classifier.pt\" files"
      ]
    },
    {
      "metadata": {
        "id": "QVvcICNN3H-5",
        "colab_type": "code",
        "outputId": "90df079e-4533-4493-93c7-6acec3c1adcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "if not isfile(data_dir + \"classify_svhn.py\"):\n",
        "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='classify_svhn.py') as pbar:\n",
        "        urlretrieve(\n",
        "            'https://github.com/CW-Huang/IFT6135H19_assignment/blob/master/assignment3/classify_svhn.py',\n",
        "            'content' + 'classify_svhn.py',\n",
        "            pbar.hook)\n",
        "        \n",
        "if not isfile(data_dir + \"svhn_classifier.pt\"):\n",
        "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='svhn_classifier.pt') as pbar:\n",
        "        urlretrieve(\n",
        "            'https://github.com/CW-Huang/IFT6135H19_assignment/blob/master/assignment3/svhn_classifier.pt',\n",
        "            data_dir + 'svhn_classifier.pt',\n",
        "            pbar.hook)\n",
        "        \n",
        "isfile(data_dir + \"classify_svhn.py\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classify_svhn.py: 106kB [00:00, 328kB/s]  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "metadata": {
        "id": "_QjPetbA2veK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ". Q3.4"
      ]
    },
    {
      "metadata": {
        "id": "8-Cu9KGb2zaw",
        "colab_type": "code",
        "outputId": "94a4a63c-5c74-484b-da04-9448c49aacb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "def image_generator(model):\n",
        "    for i in range(1000):\n",
        "        z = torch.randn(1, 100).to('cuda')\n",
        "        sample = model.decode(z).to('cuda')\n",
        "        save_image(sample.data.view(-1, 3, 32, 32).cpu(), ('Q3_4/subfolder/sample_' +str(i)+'.png'),normalize=True)\n",
        "\n",
        "\n",
        "!mkdir Q3_4\n",
        "!mkdir Q3_4/subfolder\n",
        "!rm -r Q3_4/subfolder/*\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import classify_svhn\n",
        "from classify_svhn import Classifier\n",
        "from scipy import linalg\n",
        "\n",
        "SVHN_PATH = \"svhn\"\n",
        "PROCESS_BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "def get_sample_loader(path, batch_size):\n",
        "    \"\"\"\n",
        "    Loads data from `[path]/samples`\n",
        "\n",
        "    - Ensure that path contains only one directory\n",
        "      (This is due ot how the ImageFolder dataset loader\n",
        "       works)\n",
        "    - Ensure that ALL of your images are 32 x 32.\n",
        "      The transform in this function will rescale it to\n",
        "      32 x 32 if this is not the case.\n",
        "\n",
        "    Returns an iterator over the tensors of the images\n",
        "    of dimension (batch_size, 3, 32, 32)\n",
        "    \"\"\"\n",
        "    data = torchvision.datasets.ImageFolder(\n",
        "        path,\n",
        "        transform=transforms.Compose([\n",
        "            transforms.Resize((32, 32), interpolation=2),\n",
        "            classify_svhn.image_transform\n",
        "        ])\n",
        "    )\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        data,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=2,\n",
        "    )\n",
        "    return data_loader\n",
        "\n",
        "\n",
        "def get_test_loader(batch_size):\n",
        "    \"\"\"\n",
        "    Downloads (if it doesn't already exist) SVHN test into\n",
        "    [pwd]/svhn.\n",
        "\n",
        "    Returns an iterator over the tensors of the images\n",
        "    of dimension (batch_size, 3, 32, 32)\n",
        "    \"\"\"\n",
        "    testset = torchvision.datasets.SVHN(\n",
        "        SVHN_PATH, split='test',\n",
        "        download=True,\n",
        "        transform=classify_svhn.image_transform\n",
        "    )\n",
        "    testloader = torch.utils.data.DataLoader(\n",
        "        testset,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "    return testloader\n",
        "\n",
        "\n",
        "def extract_features(classifier, data_loader):\n",
        "    \"\"\"\n",
        "    Iterator of features for each image.\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        for x, _ in data_loader:\n",
        "            h = classifier.extract_features(x).numpy()\n",
        "            for i in range(h.shape[0]):\n",
        "                yield h[i]\n",
        "\n",
        "\n",
        "def calculate_fid_score(sample_feature_iterator,\n",
        "                       testset_feature_iterator):\n",
        "    eps = 1e-2\n",
        "    sample_feature = []\n",
        "    testset_feature = []\n",
        "    for i in sample_feature_iterator:\n",
        "        sample_feature.append(i)\n",
        "    mu = np.mean(sample_feature, axis = 0)\n",
        "    sigma = np.cov(sample_feature, rowvar = False)\n",
        "    for j in testset_feature_iterator:\n",
        "        testset_feature.append(j)\n",
        "    mu1 = np.mean(testset_feature, axis = 0)\n",
        "    sigma1 = np.cov(testset_feature, rowvar = False)\n",
        "#    fid = np.linalg.norm(mu1 - mu)**2 + np.trace(sigma + sigma1 - 2 * (sigma * sigma1)**0.5)\n",
        "    fid = np.linalg.norm(mu1 - mu)**2 + np.trace(sigma + sigma1 - 2 * linalg.sqrtm(sigma.dot(sigma1)+eps*np.eye(len(sigma))))\n",
        "\n",
        "    #raise NotImplementedError(\n",
        "        #print(\"TO BE IMPLEMENTED.Part of Assignment 3 Quantitative Evaluations\")\n",
        "    #)\n",
        "    return fid\n",
        "\n",
        "def show_fid(model, directory):\n",
        "    classifier = torch.load(model, map_location = 'cpu')\n",
        "    classifier.eval()\n",
        "    sample_loader = get_sample_loader(directory, PROCESS_BATCH_SIZE)\n",
        "    sample_f = extract_features(classifier, sample_loader)\n",
        "    test_loader = get_test_loader(PROCESS_BATCH_SIZE)\n",
        "    test_f = extract_features(classifier, test_loader)\n",
        "    fid_score = calculate_fid_score(sample_f, test_f)\n",
        "    print(\"FID score:\", fid_score)\n",
        "    return fid_score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘Q3_4’: File exists\n",
            "mkdir: cannot create directory ‘Q3_4/subfolder’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IXehZAhOz4Ct",
        "colab_type": "code",
        "outputId": "74911b99-e4cc-44ad-fd42-44150c7b75e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1008
        }
      },
      "cell_type": "code",
      "source": [
        "lr = 2*1e-3\n",
        "epochs = 10\n",
        "FID = []\n",
        "for epoch in tqdm.trange(epochs, leave=True):\n",
        "    track = trainVAE(epoch)\n",
        "    testVAE(epoch)\n",
        "    \n",
        "    sample_generator(model, 100, 100, epoch)\n",
        "    \n",
        "    image_generator(model)\n",
        "    FID.append(show_fid('svhn_classifier.pt', 'Q3_4'))\n",
        "\n",
        "\n",
        "torch.save(model.state_dict(), 'VAE_model.pt')\n",
        "    \n",
        "disentangled_representation(model, 100, 7)\n",
        "interpolation(model)\n",
        "print(\"best FID:\", np.min(FID))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "====> Epoch: 0 ELBO for training: -100.4334\n",
            "====> Epoch: 0 ELBO for validation: -72.5513\n",
            "Using downloaded and verified file: svhn/test_32x32.mat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 10%|█         | 1/10 [01:25<12:48, 85.36s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "FID score: 88911.7870973881\n",
            "====> Epoch: 1 ELBO for training: -80.3882\n",
            "====> Epoch: 1 ELBO for validation: -62.4455\n",
            "Using downloaded and verified file: svhn/test_32x32.mat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 20%|██        | 2/10 [02:52<11:28, 86.02s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "FID score: 87884.0588438147\n",
            "====> Epoch: 2 ELBO for training: -69.0767\n",
            "====> Epoch: 2 ELBO for validation: -45.8138\n",
            "Using downloaded and verified file: svhn/test_32x32.mat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 30%|███       | 3/10 [04:22<10:10, 87.15s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "FID score: 66044.17745614491\n",
            "====> Epoch: 3 ELBO for training: -58.1784\n",
            "====> Epoch: 3 ELBO for validation: -45.9656\n",
            "Using downloaded and verified file: svhn/test_32x32.mat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 40%|████      | 4/10 [05:50<08:44, 87.44s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "FID score: 75265.41285850503\n",
            "====> Epoch: 4 ELBO for training: -53.6094\n",
            "====> Epoch: 4 ELBO for validation: -33.4885\n",
            "Using downloaded and verified file: svhn/test_32x32.mat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 50%|█████     | 5/10 [07:18<07:17, 87.56s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "FID score: 68240.02785578088\n",
            "====> Epoch: 5 ELBO for training: -50.4425\n",
            "====> Epoch: 5 ELBO for validation: -32.0367\n",
            "Using downloaded and verified file: svhn/test_32x32.mat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 60%|██████    | 6/10 [08:46<05:50, 87.58s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "FID score: (73988.90433525061-1.1154312184595864e-17j)\n",
            "====> Epoch: 6 ELBO for training: -48.3113\n",
            "====> Epoch: 6 ELBO for validation: -30.2501\n",
            "Using downloaded and verified file: svhn/test_32x32.mat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 70%|███████   | 7/10 [10:14<04:23, 87.86s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "FID score: 68012.41346068356\n",
            "====> Epoch: 7 ELBO for training: -46.4180\n",
            "====> Epoch: 7 ELBO for validation: -28.2485\n",
            "Using downloaded and verified file: svhn/test_32x32.mat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 80%|████████  | 8/10 [11:42<02:55, 87.85s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "FID score: 71683.41127404131\n",
            "====> Epoch: 8 ELBO for training: -46.0002\n",
            "====> Epoch: 8 ELBO for validation: -32.4800\n",
            "Using downloaded and verified file: svhn/test_32x32.mat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 90%|█████████ | 9/10 [13:08<01:27, 87.24s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "FID score: 75437.92624642575\n",
            "====> Epoch: 9 ELBO for training: -44.0202\n",
            "====> Epoch: 9 ELBO for validation: -25.5911\n",
            "Using downloaded and verified file: svhn/test_32x32.mat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 10/10 [14:36<00:00, 87.54s/it]\u001b[A\n",
            "\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "FID score: 77286.84978076266\n",
            "[16 62 52 38 22 13 92 27 55 88]\n",
            "best FID: (66044.17745614491+0j)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yCG3zUX6EnVg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#model = torch.load('VAE_model.pt', map_location='gpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O6GHMkXME86Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Playground"
      ]
    },
    {
      "metadata": {
        "id": "PaMqQzu3E6aR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "interpolation(model)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}